---

title: "Use of UAS Imagery to Detect Prairie Dog Burrows, Map Burrow Density, and Estimate Colony Acreage"
description: "Use of UAS Imagery to Detect Prairie Dog Burrows, Map Burrow Density, and Estimate Colony Acreage"
categories: [Stories]
excerpt: "Dr. Kearney is using unmanned aerial system (UAS) imagery to detect individual prairie dog burrows, map burrow density and, ultimately, estimate colony acreage within managed rangelands."

feature-img-src: /assets/img/posts/2022-10-kearney-1.jpg
feature-img-alt: "A black-tailed prairie dog at the entrance to one of its burrows at the Central Plains Experimental Range in Colorado"
featured: home

author: Sean Patrick Kearney
affiliation: Spatial Ecologist; USDA-ARS Rangeland Resources and Systems Research Unit, Fort Collins, Colorado; Thunder Basin Prairie Ecosystem Association, Douglas, Wyoming

---

![Figure 1]({{ site.baseurl }}/assets/img/posts/2022-10-kearney-1.jpg)

*Figure 1. A black-tailed prairie dog at the entrance to one of its burrows at the Central Plains Experimental Range in Colorado.*

Dr. Kearney is using unmanned aerial system (UAS) imagery to detect individual prairie dog burrows, map burrow density and, ultimately, estimate colony acreage within managed rangelands. Prairie dog colony mapping is critical to a number of rangeland management decisions on public lands; however,regular ground mapping of colonies is untenable in most areas due to high costs, extensive and rough terrain, and the dynamic boom-bust nature of prairie dog populations.

This project is utilizing SCINet resources to analyze the multi-terabyte datasets associated with UAS imagery and train a deep neural network for burrow detection. The ongoing project is a collaboration between USDA-ARS, USFS’s Geospatial Technology and Application Center (GTAC) and the Thunder Basin Prairie Grasslands Ecosystem Association (TBGPEA) and was funded, in part, through a 2021 ARS AI Center of Excellence Innovation Fund award. The study was conducted at the USDA-ARS Central Plains Experimental Range, an LTAR site with extensive ground data for training and validation. GTAC conducted the UAS flights and initial image processing.

To digitize training and validation data from the imagery, Dr. Kearney set up an interactive Python app utilizing JupyterHub on Ceres, one of SCINet’s two high-performance computing (HPC) clusters. He and other team members used this app to label burrows visible in RGB, NDVI and fine-scale topographic position layers developed in a separate Python workflow also run on Ceres. The next step was to train a deep neural network image segmentation model that could classify individual burrows using the RGB, NDVI and topographic position layers as inputs, and then validate the model against an independent test dataset. Since the goal of this project was to inform future operational mapping efforts, it was important to understand which input layers were required, and whether coarser resolution imagery would be adequate. Therefore, the training and validation procedure was repeated for different combinations of inputs and at progressively coarser spatial resolutions, resulting in dozens of iterations. The large, distributed computing and GPU resources of Ceres were essential for conducting this iterative analysis efficiently.

Initial results are very encouraging. Precision and recall of individual burrows were about 85% using imagery at its original spatial resolution, and imagery could be coarsened to up to 15 cm before results were no longer acceptable. Total acreage estimations were within about 10% of ground measurements (which themselves contain known errors) using all image resolutions between 2 – 15 cm. The final workflow to predict colony extents from the original imagery can be run in just a few hours on the Ceres cluster.

This workflow may prove to be a game-changer in rangeland monitoring, not only for prairie dogs but for vegetation (e.g., shrub detection, species or community mapping), hydrology (e.g., seasonal water sources or playas) and other applications. The ability to develop in Python using Jupyter notebooks on SCINet will facilitate transfer of the workflow to an operational monitoring system in the future.

![Figure 2]({{ site.baseurl }}/assets/img/posts/2022-10-kearney-2.jpg)

*Figure 2. Cattle observing the UAS system used to acquire imagery for the study. The vertical take-off and landing capability and fixed-wing design allowed efficient image acquisition over large areas, resulting in a very large dataset requiring SCINet resources for processing.*
